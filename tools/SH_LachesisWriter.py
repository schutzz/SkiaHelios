import pandas as pd
import polars as pl
from datetime import datetime, timedelta
import os
from pathlib import Path
import json
import re
import traceback
from tools.SH_ThemisLoader import ThemisLoader

# [IMPORT] Tartaros for Origin Tracing
try:
    from tools.SH_TartarosTracer import TartarosTracer
except ImportError:
    TartarosTracer = None

# ============================================================
#  SH_LachesisWriter v4.45 [Deep Insight Edition]
#  Mission: Weave the Grimoire with accurate Scope & Origins.
#  Update: LNK Cross-Reference & Evidence-Based Origin Tracing.
# ============================================================

TEXT_RES = {
    "en": { "title": "Incident Report", "cats": {} },
    "jp": {
        "title": "„Ç§„É≥„Ç∑„Éá„É≥„ÉàË™øÊüªÂ†±ÂëäÊõ∏",
        "coc_header": "Ë®ºÊã†‰øùÂÖ®„Åä„Çà„Å≥Ê°à‰ª∂ÊÉÖÂ†± (Chain of Custody)",
        "h1_exec": "1. „Ç®„Ç∞„Çº„ÇØ„ÉÜ„Ç£„Éñ„Éª„Çµ„Éû„É™„Éº",
        "h1_origin": "2. ÂàùÊúü‰æµÂÖ•ÁµåË∑ØÂàÜÊûê (Initial Access Vector)",
        "h1_time": "3. Ë™øÊüª„Çø„Ç§„É†„É©„Ç§„É≥ (Critical Chain)",
        "h1_tech": "4. ÊäÄË°ìÁöÑË©≥Á¥∞ (High Confidence Findings)",
        "h1_stats": "5. Ê§úÁü•Áµ±Ë®à (Medium Confidence / Filtered Noise)",
        "h1_rec": "6. ÁµêË´ñ„Å®Êé®Â•®‰∫ãÈ†Ö",
        "h1_app": "7. Ê∑ª‰ªòË≥áÊñô (Critical IOCs Only)",
        "cats": {"INIT": "ÂàùÊúü‰æµÂÖ•", "C2": "C2ÈÄö‰ø°", "PERSIST": "Ê∞∏Á∂öÂåñ", "ANTI": "ÁóïË∑°Èö†ÊªÖ", "EXEC": "ÂÆüË°å", "DROP": "„Éï„Ç°„Ç§„É´‰ΩúÊàê", "WEB": "Web„Ç¢„ÇØ„Çª„Çπ"},
    }
}

class LachesisWriter:
    def __init__(self, lang="jp", hostname="Unknown_Host", case_name="Investigation"):
        self.lang = lang if lang in TEXT_RES else "jp"
        self.txt = TEXT_RES[self.lang]
        self.hostname = hostname
        self.case_name = case_name
        self.visual_iocs = []
        self.infra_ips_found = set()
        self.loader = ThemisLoader(["rules/triage_rules.yaml"])
        self.dual_use_keywords = self.loader.get_dual_use_keywords()
        self.pivot_seeds = []
        self.noise_stats = {}

    def _is_trusted_system_path(self, path):
        p = str(path).lower().replace("\\", "/")
        trusted_roots = [
            "c:/windows/", "c:/program files/", "c:/program files (x86)/",
            "{windows}", "{system32}", "{program files", "{common program files"
        ]
        suspicious_subdirs = ["/temp", "/tmp", "/users/public", "/appdata", "/programdata", "downloads", "documents", "desktop"]
        if any(s in p for s in suspicious_subdirs): return False
        return any(root in p for root in trusted_roots)

    def _is_noise(self, name, path=""):
        name = str(name).strip().lower()
        path = str(path).strip().lower().replace("\\", "/")
        garbage_paths = [
            "appdata/local/google/chrome", "appdata/roaming/microsoft/spelling",
            "appdata/roaming/skype", "appdata/local/packages", 
            "windows/assembly", "windows/servicing", "windows/prefetch", 
            "inetcache", "tkdata", "thumbcache", "iconcache",
            "windows/notifications", "appdata/local/microsoft/windows/notifications"
        ]
        for gp in garbage_paths:
            if gp in path:
                self._log_noise("Garbage Path", gp)
                return True
        if re.match(r'^[a-f0-9]{32,64}$', name): return True
        if name.endswith(".db") or name.endswith(".dat") or name.endswith(".log"): return True
        return False

    def _log_noise(self, reason, value):
        if reason not in self.noise_stats: self.noise_stats[reason] = 0
        self.noise_stats[reason] += 1

    def _is_dual_use(self, name):
        name_lower = str(name).lower()
        return any(k in name_lower for k in self.dual_use_keywords)
    
    # [Task 1] Helper Method for Cross-Reference
    def _enrich_from_timeline(self, filename, timeline_df):
        """
        [Cross-Reference] Timeline„Åã„ÇâË©≥Á¥∞ÊÉÖÂ†±„ÇíÊäΩÂá∫
        Returns: target_path, tag, args, is_executed(bool)
        """
        if timeline_df is None or not filename:
            return None, None, None, False
            
        try:
            import os
            search_key = str(filename).lower()
            if "\\" in search_key or "/" in search_key:
                search_key = os.path.basename(search_key.replace("\\", "/"))

            exprs = []
            if "FileName" in timeline_df.columns:
                exprs.append(pl.col("FileName").str.to_lowercase().str.contains(search_key, literal=True))
            
            msg_cols = [c for c in timeline_df.columns if "message" in c.lower()]
            if msg_cols:
                exprs.append(pl.col(msg_cols[0]).str.to_lowercase().str.contains(search_key, literal=True))
            
            if not exprs:
                return None, None, None, False
                
            combined_expr = exprs[0]
            for e in exprs[1:]:
                combined_expr = combined_expr | e
                
            matched = timeline_df.filter(combined_expr)
            
            if matched.height > 0:
                row = matched.row(0, named=True)
                target = row.get("Target_Path", "")
                tag = row.get("Tag", "")
                
                args = row.get("Arguments", "")
                if not args:
                    for col in row.keys():
                        val = str(row[col])
                        if "Arguments:" in val:
                            try:
                                args = val.split("Arguments:", 1)[1].split("  ")[0].strip()
                            except: pass
                            if args: break
                
                # Check Execution Evidence
                is_executed = False
                exec_artifacts = ["Process", "Prefetch", "UserAssist", "Shimcache", "Amcache"]
                if "Artifact_Type" in matched.columns:
                     exec_rows = matched.filter(pl.col("Artifact_Type").str.contains("|".join(exec_artifacts)))
                     if exec_rows.height > 0:
                         is_executed = True
                
                if "EXECUTION_CONFIRMED" in tag:
                    is_executed = True

                return target, tag, args, is_executed
        except Exception as e:
            pass
        return None, None, None, False
    
    def _is_high_confidence(self, ev):
        """
        [Phase 2] Force Include Logic„ÅÆÂÆüË£Ö
        """
        summary = str(ev.get('Summary', ''))
        category = str(ev.get('Category', ''))
        tag = str(ev.get('Tag', '')).upper()
        
        force_keywords = [
            "TIME_PARADOX", "CRITICAL_MASQUERADE", "CRITICAL_PHISHING", 
            "SUSPICIOUS_CMDLINE", "CRITICAL_SIGMA", "ROLLBACK"
        ]
        if any(k in summary.upper() for k in force_keywords):
            return True
        if any(k in tag for k in force_keywords):
            return True
            
        try:
            score = int(ev.get('Criticality', 0))
            if score >= 80: return True
        except: pass

        if category in ["PERSIST", "LATERAL", "EXFIL"]:
            return True
        return False
    
    def _parse_time_safe(self, time_str):
        if not time_str: return None
        s = str(time_str).replace("Z", "")
        if "." in s and len(s) > 26: s = s[:26]
        try: return datetime.fromisoformat(s)
        except: return None
        
    def _is_visual_noise(self, name):
        name = str(name).strip()
        if len(name) < 3: return True
        return False

    def _auto_find_history_csv(self, base_paths):
        """Deep Disk-based discovery."""
        if isinstance(base_paths, (str, Path)): base_paths = [base_paths]
        
        search_dirs = [Path(p) for p in base_paths if p]
        
        expanded_dirs = []
        for d in search_dirs:
            if d.exists():
                candidates = [d]
                if d.is_file(): candidates = [d.parent, d.parent.parent, d.parent.parent.parent]
                else: candidates = [d, d.parent, d.parent.parent]
                
                for c in candidates:
                    try: 
                        if c.exists() and c not in expanded_dirs: expanded_dirs.append(c)
                    except: pass
        
        inferred_roots = self._infer_source_roots(self._latest_dfs)
        if inferred_roots:
            print(f"    [Lachesis] [Brain] Inferred Source Roots: {[str(r) for r in inferred_roots]}")
            for r in inferred_roots:
                if r.exists() and r not in expanded_dirs: expanded_dirs.append(r)

        patterns = ["*History*.csv", "*Web*.csv", "*Chrome*.csv", "*Browsing*.csv", "*Edge*.csv"]
        print(f"    [Lachesis] [Scan] Scanning {len(expanded_dirs)} locations for Browser History...")
        
        for d in expanded_dirs:
            if d.is_file(): d = d.parent 
            try:
                for pat in patterns:
                    for f in d.rglob(pat):
                        if "Grimoire" in f.name: continue
                        print(f"    [Lachesis] [OK] Found Candidate: {f}")
                        return str(f.resolve())
            except Exception as e:
                pass
        return None

    def _infer_source_roots(self, dfs):
        roots = set()
        try:
            if dfs and dfs.get('Timeline') is not None:
                df = dfs['Timeline']
                cols = df.columns
                target_col = "Source" if "Source" in cols else ("Source_File" if "Source_File" in cols else None)
                if target_col:
                    sample = df.head(20)
                    for row in sample.iter_rows(named=True):
                        val = str(row.get(target_col, ""))
                        if ":" in val and ("\\" in val or "/" in val):
                            path = Path(val)
                            try:
                                parts = path.parts
                                fs_idx = -1
                                for i, p in enumerate(parts):
                                    if p.lower() in ["filesystem", "kape", "triage", "artifacts", "c"]: fs_idx = i
                                
                                if fs_idx > 0:
                                    root_path = Path(*parts[:fs_idx])
                                    roots.add(root_path)
                                    roots.add(root_path.parent)
                                else:
                                    curr = path
                                    if curr.is_file(): curr = curr.parent
                                    for _ in range(5):
                                        roots.add(curr)
                                        curr = curr.parent
                                        if len(curr.parts) <= 1: break
                            except: pass
        except: pass
        return list(roots)

    def _resolve_os_info_fallback(self, provided_os, outdir):
        if provided_os and "Auto-Detected" not in provided_os and "Unknown" not in provided_os:
            return provided_os
        meta_path = Path(outdir) / "Case_Metadata.json"
        if meta_path.exists():
            try:
                with open(meta_path, 'r', encoding='utf-8') as f:
                    meta = json.load(f)
                    val = meta.get("OS_Info")
                    if val and "Unknown" not in val: return val
            except: pass
        return provided_os

    def _resolve_history_df(self, dfs):
        candidates = ["BrowsingHistory", "WebHistory", "Chrome_History", "Edge_History", "Firefox_History", "History"]
        for key in dfs.keys():
            for cand in candidates:
                if cand.lower() in key.lower():
                    print(f"    [Lachesis] ‚úÖ Auto-Discovered History Data (Memory): {key}")
                    return dfs[key]
        return None

    def weave_report(self, analysis_result, output_path, dfs_for_ioc, hostname, os_info, primary_user, history_csv=None, history_search_path=None):
        print(f"[*] Lachesis v4.45 is weaving the report into {output_path}...")
        self.hostname = hostname 
        self._latest_dfs = dfs_for_ioc
        raw_events = analysis_result["events"]
        self.noise_stats = {}

        real_os_info = self._resolve_os_info_fallback(os_info, Path(output_path).parent)

        high_crit_times = []
        critical_events = []
        medium_events = []

        for ev in raw_events:
            try: score = int(float(ev.get('Criticality', 0)))
            except: score = 0
            summary = ev.get('Summary', '')
            tag = str(ev.get('Tag', '')).upper()
            is_dual = self._is_dual_use(summary)
            
            is_crit_std = False
            if score >= 200: is_crit_std = True
            elif is_dual and score >= 80: is_crit_std = True
            elif "CRITICAL" in str(ev.get('Category', '')).upper(): is_crit_std = True
            elif "CRITICAL" in tag or "ACTIVE" in tag: is_crit_std = True
            
            force_include_tags = ["TIME_PARADOX", "MASQUERADE", "PHISHING", "SUSPICIOUS_CMDLINE", "ROLLBACK"]
            if any(k in tag for k in force_include_tags):
                is_crit_std = True
            
            if is_crit_std: critical_events.append(ev)
            elif score >= 80: medium_events.append(ev)

            chk_score = score
            for k in ['Threat_Score', 'Chronos_Score', 'AION_Score']:
                try: 
                    s = int(float(ev.get(k, 0)))
                    if s > chk_score: chk_score = s
                except: pass
            
            chk_tag = tag + str(ev.get('Threat_Tag', "")).upper()
            chk_name = str(ev.get('FileName', "") or ev.get('Ghost_FileName', "") or ev.get('Target_FileName', "") or summary).lower()
            
            if chk_score >= 200 or "CRITICAL" in chk_tag or "MASQUERADE" in chk_tag or "TIMESTOMP" in chk_tag or "PHISHING" in chk_tag or "PARADOX" in chk_tag or self._is_dual_use(chk_name):
                t_val = ev.get('Time') or ev.get('Ghost_Time_Hint') or ev.get('Last_Executed_Time')
                dt = self._parse_time_safe(t_val)
                if dt and dt.year >= 2016:  
                    high_crit_times.append(dt)

        if high_crit_times:
            high_crit_times = sorted(set(high_crit_times))
            core_start = min(high_crit_times) - timedelta(hours=3)
            core_end = max(high_crit_times) + timedelta(hours=3)
            time_range = f"{core_start.strftime('%Y-%m-%d %H:%M')} „Äú {core_end.strftime('%H:%M')} (UTC)"
        else:
            time_range = "Unknown Range (No Critical Events)"

        phases = [critical_events] if critical_events else []
        self.visual_iocs = [] 
        self.pivot_seeds = []
        
        self._extract_visual_iocs_from_pandora(dfs_for_ioc)
        self._extract_visual_iocs_from_chronos(dfs_for_ioc)
        self._extract_visual_iocs_from_aion(dfs_for_ioc)
        self._extract_visual_iocs_from_events(raw_events)
        
        self._generate_pivot_seeds()
        
        force_include_types = ["TIME_PARADOX", "CRITICAL_MASQUERADE", "CRITICAL_PHISHING", "TIMESTOMP", "CREDENTIALS"]
        for ioc in self.visual_iocs:
            ioc_type = str(ioc.get("Type", "")).upper()
            if any(k in ioc_type for k in force_include_types):
                ioc_time = ioc.get("Time", "")
                dt = self._parse_time_safe(ioc_time)
                if dt and dt.year >= 2016:
                    high_crit_times.append(dt)
        
        if high_crit_times:
            high_crit_times = sorted(set(high_crit_times))
            core_start = min(high_crit_times) - timedelta(hours=3)
            core_end = max(high_crit_times) + timedelta(hours=3)
            time_range = f"{core_start.strftime('%Y-%m-%d %H:%M')} „Äú {core_end.strftime('%H:%M')} (UTC)"

        origin_stories = []
        if self.pivot_seeds and TartarosTracer:
            timeline_df = dfs_for_ioc.get("Timeline")
            df_history_target = self._resolve_history_df(dfs_for_ioc)
            
            if not history_csv and df_history_target is None:
                search_roots = []
                if history_search_path: search_roots.append(history_search_path)
                search_roots.append(Path(output_path).parent)
                search_roots.append(".") 
                history_csv = self._auto_find_history_csv(search_roots)

            if history_csv or timeline_df is not None or df_history_target is not None:
                try:
                    print("    -> [Lachesis] Invoking Tartaros for Origin Tracing...")
                    tracer = TartarosTracer(history_csv=history_csv)
                    origin_stories = tracer.trace_memory(self.pivot_seeds, timeline_df, df_history=df_history_target)
                    print(f"    -> [Lachesis] Tartaros Stories Found: {len(origin_stories)}")
                except Exception as e: 
                    print(f"    [!] Tartaros Trace Failed: {e}")
                    traceback.print_exc()

        out_file = Path(output_path)
        with open(out_file, "w", encoding="utf-8") as f:
            self._write_header(f, real_os_info, primary_user, time_range)
            self._write_toc(f)
            self._write_executive_summary_visual(f, critical_events, analysis_result["verdict_flags"], primary_user, time_range)
            self._write_initial_access_vector(f, self.pivot_seeds, origin_stories)
            self._write_timeline_visual(f, phases)
            self._write_technical_findings(f, phases)
            self._write_detection_statistics(f, medium_events, dfs_for_ioc)
            self._write_ioc_appendix_unified(f) 
            f.write(f"\n---\n*Report woven by SkiaHelios (The Triad v4.45)* ü¶Å")
        
        json_path = out_file.with_suffix('.json')
        self._export_json_grimoire(analysis_result, dfs_for_ioc, json_path, primary_user)
        pivot_path = out_file.parent / "Pivot_Config.json"
        self._export_pivot_config(pivot_path, primary_user)

    def _write_header(self, f, os_info, primary_user, time_range):
        t = self.txt
        f.write(f"# {t['title']} - {self.hostname}\n\n")
        f.write(f"### üõ°Ô∏è {t['coc_header']}\n")
        f.write("| Item | Details |\n|---|---|\n")
        f.write(f"| **Target Host** | **{self.hostname}** |\n")
        f.write(f"| **OS Info** | {os_info} |\n") 
        f.write(f"| **Primary User** | {primary_user} |\n")
        f.write(f"| **Incident Scope** | **{time_range}** |\n") 
        f.write(f"| **Report Date** | {datetime.now().strftime('%Y-%m-%d')} |\n\n---\n\n")

    def _write_toc(self, f):
        t = self.txt
        f.write("## üìö Table of Contents\n")
        f.write(f"- [{t['h1_exec']}](#{self._make_anchor(t['h1_exec'])})\n")
        f.write(f"- [{t['h1_origin']}](#{self._make_anchor(t['h1_origin'])})\n")
        f.write(f"- [{t['h1_time']}](#{self._make_anchor(t['h1_time'])})\n")
        f.write(f"- [{t['h1_tech']}](#{self._make_anchor(t['h1_tech'])})\n")
        f.write(f"- [{t['h1_stats']}](#{self._make_anchor(t['h1_stats'])})\n")
        f.write(f"- [{t['h1_app']}](#{self._make_anchor(t['h1_app'])})\n")
        f.write(f"- [Pivot Config (Deep Dive Targets)](#deep-dive-recommendation)\n")
        f.write("\n---\n\n")

    def _make_anchor(self, text):
        return text.lower().replace(" ", "-").replace(".", "").replace("&", "").replace("(", "").replace(")", "").replace("/", "")

    def _write_initial_access_vector(self, f, pivot_seeds, origin_stories):
        t = self.txt
        f.write(f"## {t['h1_origin']}\n")
        phishing_lnks = [s for s in pivot_seeds if "PHISHING" in s.get("Reason", "")]
        drop_items = [s for s in pivot_seeds if "DROP" in s.get("Reason", "") and "PHISHING" not in s.get("Reason", "")]
        
        if phishing_lnks:
            f.write("**„Éï„Ç£„ÉÉ„Ç∑„É≥„Ç∞„Å´„Çà„ÇãÂàùÊúü‰æµÂÖ•„ÅåÈ´òÁ¢∫Â∫¶„ÅßÁ¢∫Ë™ç„Åï„Çå„Åæ„Åó„Åü„ÄÇ**\n")
            f.write(f"- Recent„Éï„Ç©„É´„ÉÄÁ≠â„Å´„Åä„ÅÑ„Å¶„ÄÅ**{len(phishing_lnks)}‰ª∂** „ÅÆ‰∏çÂØ©„Å™LNK„Éï„Ç°„Ç§„É´Ôºà„Ç∑„Éß„Éº„Éà„Ç´„ÉÉ„ÉàÔºâ„Å∏„ÅÆ„Ç¢„ÇØ„Çª„Çπ„ÅåÊ§úÁü•„Åï„Çå„Å¶„ÅÑ„Åæ„Åô„ÄÇ\n")
            f.write("\n| „Çµ„É≥„Éó„É´LNK | „Ç¢„ÇØ„Çª„ÇπÊôÇÂàª (UTC) | ÊµÅÂÖ•ÂÖÉ (Origin Trace) |\n|---|---|---|\n")
            for seed in phishing_lnks[:10]:
                self._write_origin_row(f, seed, origin_stories)
            f.write("\n")

        if drop_items:
            f.write("**‰∏çÂØ©„Å™„ÉÑ„Éº„É´„Éª„Éï„Ç°„Ç§„É´„ÅÆÊåÅ„Å°Ëæº„ÅøÔºàDropped ArtifactsÔºâ:**\n")
            f.write("\n| „Éï„Ç°„Ç§„É´Âêç | Áô∫Ë¶ãÂ†¥ÊâÄ | ÊµÅÂÖ•ÂÖÉ (Origin Trace) |\n|---|---|---|\n")
            for seed in drop_items[:10]:
                self._write_origin_row(f, seed, origin_stories)
            f.write("\n")

        if not phishing_lnks and not drop_items:
            f.write("ÊòéÁ¢∫„Å™Â§ñÈÉ®‰æµÂÖ•„Éô„ÇØ„Çø„Éº„ÅØËá™ÂãïÊ§úÁü•„Åï„Çå„Åæ„Åõ„Çì„Åß„Åó„Åü„ÄÇ\n\n")

    # [Task 2] Updated Origin Row with Confidence
    def _write_origin_row(self, f, seed, origin_stories):
        name = seed['Target_File']
        time = str(seed.get('Timestamp_Hint', '')).replace('T', ' ')[:19]
        
        origin_desc = "‚ùì No Trace Found (Low Confidence)"
        
        story = next((s for s in origin_stories if s["Target"] == name), None)
        
        if story:
            ev = story["Evidence"][0]
            url = ev.get("URL", "")
            url_display = (url[:50] + "...") if len(url) > 50 else url
            gap = ev.get('Time_Gap', '-')
            conf = story.get("Confidence", "LOW")
            reason = story.get("Reason", "")
            
            if conf == "HIGH":
                icon = "‚úÖ" 
                prefix = "**Confirmed**"
            elif conf == "MEDIUM":
                icon = "‚ö†Ô∏è"
                prefix = "Inferred"
            else:
                icon = "‚ùì"
                prefix = "Weak"

            origin_desc = f"{icon} **{prefix}**: {reason}<br/>üîó `{url_display}`<br/>*(Gap: {gap})*"
        
        col2 = time if time else f"`{seed.get('Target_Path', '')[:20]}`"
        f.write(f"| `{name}` | {col2} | {origin_desc} |\n")

    def _extract_visual_iocs_from_chronos(self, dfs):
        if dfs.get('Chronos') is not None:
            df = dfs['Chronos']
            cols = df.columns
            score_col = "Chronos_Score" if "Chronos_Score" in cols else "Threat_Score"
            if score_col in cols:
                try:
                    df_sorted = df.sort(score_col, descending=True)
                    for row in df_sorted.iter_rows(named=True):
                        fname = row.get("FileName") or ""
                        path = row.get("ParentPath") or ""
                        score = int(float(row.get(score_col, 0)))
                        
                        bypass_reason = None
                        is_trusted_loc = self._is_trusted_system_path(path)
                        is_dual = self._is_dual_use(fname)

                        if "ROLLBACK" in str(row.get("Anomaly_Time", "")):
                            bypass_reason = "üö® SYSTEM TIME ROLLBACK DETECTED üö®"
                            if not fname and path: fname = f"System Artifact ({path})"
                            self._log_noise("TIME PARADOX", f"{fname} triggered Rollback Alert")
                            self._add_unique_visual_ioc({
                                "Type": "TIME_PARADOX", 
                                "Value": fname if fname else "Unknown", 
                                "Path": path, 
                                "Note": str(row.get("Anomaly_Time", "")), 
                                "Time": str(row.get("si_dt", "") or row.get("UpdateTimestamp", "")),
                                "Reason": bypass_reason,
                                "Score": score  # [ËøΩÂä†] Score„Çí‰øùÂ≠ò
                            })
                            continue

                        # [ËøΩÂä†„ÉªÂ§âÊõ¥] Timestomp Execution Check
                        extra_info = {}
                        timeline_df = dfs.get('Timeline')
                        if is_dual or "TIMESTOMP" in str(row.get("Threat_Tag", "")):
                             _, _, _, is_executed = self._enrich_from_timeline(fname, timeline_df)
                             extra_info["Execution"] = is_executed

                        if is_dual:
                            bypass_reason = "Dual-Use Tool [DROP]" 
                        elif score >= 220:
                            if is_trusted_loc:
                                self._log_noise("Trusted Path (Update)", fname)
                                continue
                            else:
                                bypass_reason = "High Score (Timestomp) [DROP]"
                        
                        if self._is_noise(fname, path):
                             self._log_noise("Explicit Noise Filter", fname)
                             continue

                        if bypass_reason:
                             if "False Positive" in bypass_reason or "NOISE" in bypass_reason: continue
                        elif score < 200: continue 
                        
                        if not bypass_reason: bypass_reason = "High Score (>200)"
                        self._add_unique_visual_ioc({
                            "Type": "TIMESTOMP", "Value": fname, "Path": path, "Note": "Time Anomaly", 
                            "Time": str(row.get("Anomaly_Time", "")), 
                            "Reason": bypass_reason, 
                            "Score": score,          # [ËøΩÂä†] Score„Çí‰øùÂ≠ò
                            "Extra": extra_info      # [ËøΩÂä†] Extra„Çí‰øùÂ≠ò
                        })
                except: pass

    # [Task 1] Updated Pandora IOC Extraction with Cross-Reference
    def _extract_visual_iocs_from_pandora(self, dfs):
        if dfs.get('Pandora') is not None:
            df = dfs['Pandora']
            timeline_df = dfs.get('Timeline') 
            
            if "Threat_Score" in df.columns:
                try:
                    df_sorted = df.sort("Threat_Score", descending=True)
                    for row in df_sorted.iter_rows(named=True):
                        fname = row.get("Ghost_FileName", "")
                        path = row.get("ParentPath", "")
                        tag = str(row.get("Threat_Tag", "")).upper()
                        score = int(float(row.get("Threat_Score", 0)))

                        bypass_reason = None
                        is_trusted_loc = self._is_trusted_system_path(path)

                        if "MASQUERADE" in tag: bypass_reason = "Critical Criteria (CRITICAL_MASQUERADE) [DROP]"
                        elif "PHISH" in tag: bypass_reason = "Critical Criteria (PHISHING) [DROP]"
                        elif "BACKDOOR" in tag: bypass_reason = "Backdoor Detected [DROP]"
                        elif "CREDENTIALS" in tag and score >= 200: bypass_reason = "Credential Dump [DROP]"
                        
                        elif is_trusted_loc:
                            self._log_noise("Trusted Path (Update)", fname)
                            continue
                        
                        if self._is_noise(fname, path):
                             self._log_noise("Explicit Noise Filter", fname)
                             continue

                        elif self._is_dual_use(fname): bypass_reason = "Dual-Use Tool [DROP]"
                        elif "TIMESTOMP" in tag: bypass_reason = "Timestomp [DROP]"
                        elif score >= 250: bypass_reason = "Critical Score [DROP]"

                        if bypass_reason: 
                            pass
                        elif score < 200: continue

                        if not bypass_reason: bypass_reason = "High Confidence"
                        clean_name = fname.split("] ")[-1]
                        
                        # [Task 1] Cross-Reference Enrichment
                        extra_info = {}
                        final_tag = tag
                        
                        if ".lnk" in fname.lower():
                            # [CHANGE] args „ÇíÂèó„ÅëÂèñ„Çã
                            target_path, timeline_tag, args, _ = self._enrich_from_timeline(fname, timeline_df)
                            
                            if target_path: extra_info["Target_Path"] = target_path
                            # [NEW] ÂºïÊï∞„ÇíÊ†ºÁ¥ç
                            if args: extra_info["Arguments"] = args
                            
                            # [NEW] „Çª„Ç≠„É•„É™„ÉÜ„Ç£„ÉÑ„Éº„É´„ÇÑ„Ç´„É≥„Éï„Ç°„É¨„É≥„Çπ„Å∏„ÅÆÂÅΩË£ÖÊ§úÁü•
                            if "DEFCON" in clean_name.upper() or "BYPASS" in clean_name.upper():
                                extra_info["Risk"] = "SECURITY_TOOL_MASQUERADE"

                            if timeline_tag:
                                merged_tags = set(tag.split(",") + timeline_tag.split(","))
                                merged_tags.discard("")
                                final_tag = ",".join(list(merged_tags))
                        
                        self._add_unique_visual_ioc({
                            "Type": final_tag,
                            "Value": clean_name, 
                            "Path": path, 
                            "Note": "File Artifact", 
                            "Time": str(row.get("Ghost_Time_Hint", "")), 
                            "Reason": bypass_reason,
                            "Extra": extra_info,
                            "Score": score # [ËøΩÂä†] Score„Çí‰øùÂ≠ò
                        })
                except: pass

    def _extract_visual_iocs_from_aion(self, dfs):
         if dfs.get('AION') is not None:
            df = dfs['AION']
            if "AION_Score" in df.columns:
                try:
                    for row in df.iter_rows(named=True):
                        try: score = int(float(row.get("AION_Score", 0)))
                        except: score = 0
                        if score >= 50:
                            name = row.get("Target_FileName")
                            if not self._is_noise(name, row.get("Full_Path", "")):
                                self._add_unique_visual_ioc({
                                    "Type": "PERSISTENCE", "Value": name, "Path": row.get("Full_Path"), "Note": "Persist", 
                                    "Time": str(row.get("Last_Executed_Time", "")), "Reason": "Persistence",
                                    "Score": score # [ËøΩÂä†] Score„Çí‰øùÂ≠ò
                                })
                except: pass

    def _extract_visual_iocs_from_events(self, events):
        re_ip = re.compile(r'\b(?:\d{1,3}\.){3}\d{1,3}\b')
        infra_ips = ["10.0.2.15", "10.0.2.2", "127.0.0.1", "0.0.0.0", "::1"]
        for ev in events:
            content = ev['Summary'] + " " + str(ev.get('Detail', ''))
            ips = re_ip.findall(content)
            for ip in ips:
                if ip in infra_ips or ip.startswith("127."): 
                    self.infra_ips_found.add(ip); continue
                parts = ip.split('.')
                if len(parts) == 4:
                    try:
                        p1 = int(parts[0]); p2 = int(parts[1])
                        if p1 < 10 and ip != "1.1.1.1" and ip != "8.8.8.8" and ip != "8.8.4.4": continue 
                    except: continue
                self._add_unique_visual_ioc({
                    "Type": "IP_TRACE", "Value": ip, "Path": "Network", "Note": f"Detected in {ev['Source']}"
                })
            
            is_dual = self._is_dual_use(ev.get('Summary', ''))
            tag = str(ev.get('Tag', '')).upper()
            is_af = "ANTI_FORENSICS" in tag
            score = ev.get('Criticality', 0) # [ËøΩÂä†]

            if (ev['Criticality'] >= 90 or is_dual or is_af) and (ev['Category'] == 'EXEC' or ev['Category'] == 'ANTI'):
                kws = ev.get('Keywords', [])
                if kws:
                    kw = str(kws[0]).lower()
                    if not self._is_noise(kw):
                        if is_af:
                            type_label = "ANTI_FORENSICS"
                            reason_label = "Evidence Destruction"
                        elif is_dual:
                            type_label = "DUAL_USE_TOOL"
                            reason_label = "Dual-Use Tool [DROP]"
                        else:
                            type_label = "EXECUTION"
                            reason_label = "Execution"

                        self._add_unique_visual_ioc({
                            "Type": type_label, "Value": kws[0], "Path": "Process", "Note": f"Execution ({ev['Source']})",
                            "Reason": reason_label,
                            "Time": ev.get('Time'),
                            "Score": score # [ËøΩÂä†]
                        })

    def _write_executive_summary_visual(self, f, events, verdicts, primary_user, time_range):
        t = self.txt
        f.write(f"## {t['h1_exec']}\n")
        
        has_paradox = any("TIME_PARADOX" in str(ioc.get('Type', '')) for ioc in self.visual_iocs)
        has_masquerade = any("MASQUERADE" in str(ioc.get('Type', '')) for ioc in self.visual_iocs)
        has_phishing = any("PHISHING" in str(ioc.get('Type', '')) for ioc in self.visual_iocs)
        has_timestomp = any("TIMESTOMP" in str(ioc.get('Type', '')) for ioc in self.visual_iocs)
        
        if "Unknown" in time_range and self.visual_iocs:
            ioc_times = []
            for ioc in self.visual_iocs:
                dt = self._parse_time_safe(ioc.get("Time", ""))
                if dt and dt.year >= 2016:
                    ioc_times.append(dt)
            if ioc_times:
                ioc_times = sorted(ioc_times)
                time_range = f"{ioc_times[0].strftime('%Y-%m-%d %H:%M')} „Äú {ioc_times[-1].strftime('%H:%M')} (UTC)"
        
        if has_paradox or has_masquerade:
            conclusion = f"**ÁµêË´ñ:**\n{time_range} „ÅÆÊúüÈñì„Å´„Åä„ÅÑ„Å¶„ÄÅÁ´ØÊú´ {self.hostname} „Å´ÂØæ„Åô„Çã **È´òÂ∫¶„Å™Èö†ËîΩÂ∑•‰Ωú„Çí‰º¥„ÅÜÈáçÂ§ß„Å™‰æµÂÆ≥Ê¥ªÂãï** „ÇíÁ¢∫Ë™ç„Åó„Åæ„Åó„Åü„ÄÇ\n"
        elif self.visual_iocs:
            conclusion = f"**ÁµêË´ñ:**\n{time_range} „ÅÆÊúüÈñì„Å´„Åä„ÅÑ„Å¶„ÄÅÁ´ØÊú´ {self.hostname} „Å´ÂØæ„Åô„Çã **CRITICAL „É¨„Éô„É´„ÅÆ‰æµÂÆ≥Ê¥ªÂãï** „ÇíÁ¢∫Ë™ç„Åó„Åæ„Åó„Åü„ÄÇ\n"
        else:
            conclusion = f"**ÁµêË´ñ:**\nÊú¨Ë™øÊüªÁØÑÂõ≤„Å´„Åä„ÅÑ„Å¶„ÄÅÈáçÂ§ß„Å™„Ç§„É≥„Ç∑„Éá„É≥„Éà„ÅÆÁóïË∑°„ÅØÊ§úÂá∫„Åï„Çå„Åæ„Åõ„Çì„Åß„Åó„Åü„ÄÇ\n"
        
        f.write(conclusion)
        
        attack_methods = []
        if has_phishing: attack_methods.append("„Éï„Ç£„ÉÉ„Ç∑„É≥„Ç∞ÔºàLNKÔºâ„Å´„Çà„ÇãÂàùÊúü‰æµÂÖ•")
        if has_masquerade: attack_methods.append("ÂÅΩË£Ö„Éï„Ç°„Ç§„É´Ë®≠ÁΩÆÔºàMasqueradingÔºâ")
        if has_timestomp: attack_methods.append("„Çø„Ç§„É†„Çπ„Çø„É≥„ÉóÂÅΩË£ÖÔºàTimestompÔºâ")
        if has_paradox: attack_methods.append("**„Ç∑„Çπ„ÉÜ„É†ÊôÇÈñìÂ∑ª„ÅçÊàª„ÅóÔºàSystem RollbackÔºâ**")
        
        if not attack_methods:
            attack_methods = ["‰∏çÂØ©„Å™„Ç¢„ÇØ„ÉÜ„Ç£„Éì„ÉÜ„Ç£"]
            
        f.write(f"**‰∏ª„Å™ÊîªÊíÉÊâãÂè£:** {', '.join(attack_methods)}„ÄÇ\n\n")
        f.write("> **Deep Dive Êé®Â•®:** Ë©≥Á¥∞„Å™Ë™øÊüª„ÇíË°å„ÅÜÈöõ„ÅØ„ÄÅÊ∑ª‰ªò„ÅÆ `Pivot_Config.json` „Å´Ë®òËºâ„Åï„Çå„Åü **CRITICAL_PHISHING** „Çø„Éº„Ç≤„ÉÉ„ÉàÁæ§„Åã„ÇâÈñãÂßã„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ\n\n")
        f.write("\n### üèπ Attack Timeline Flow (Critical Chain)\n")
        if self.visual_iocs: f.write(self._generate_mermaid())
        else: f.write("(No sufficient visual indicators found)\n")

        # [NEW] Enhanced Table Logic
        f.write("\n### üíé Key Indicators (Critical Only)\n")
        if self.visual_iocs:
            # „Éò„ÉÉ„ÉÄ„ÉºÂ§âÊõ¥: Target/Action „Å® Score „ÇíËøΩÂä†
            f.write("| Time | Type | Value (File/IP) | **Target / Action** | **Score** | Path |\n|---|---|---|---|---|---|\n")
            
            sorted_iocs = sorted(self.visual_iocs, key=lambda x: x.get("Time", "9999"))
            seen = set()
            for ioc in sorted_iocs:
                val = ioc['Value']
                if val in seen: continue
                seen.add(val)
                
                # Determine Target/Action Content
                target_action = "-"
                extra = ioc.get("Extra", {})
                ioc_type = str(ioc.get("Type", "")).upper()
                reason = str(ioc.get("Reason", "")).upper()
                
                if ".lnk" in val.lower() or "PHISHING" in ioc_type:
                    tgt = extra.get("Target_Path", "")
                    if not tgt and "Target:" in ioc.get("Value", ""):
                        tgt = ioc.get("Value", "").split("Target:")[-1].strip()
                    # „Çø„Éº„Ç≤„ÉÉ„Éà„Åå„ÅÇ„Çå„Å∞Ë°®Á§∫
                    target_action = f"üéØ {tgt[:40] + '..' if len(tgt)>40 else tgt}" if tgt else "Target Unknown"
                
                elif "TIMESTOMP" in ioc_type:
                    # Check execution evidence (Extra flag or Tag context)
                    if extra.get("Execution") == True or "EXECUTION" in reason or "EXECUTION_CONFIRMED" in ioc_type:
                        target_action = "‚úÖ ÂÆüË°åÁóïË∑°„ÅÇ„Çä"
                    else:
                        target_action = "‚ö†Ô∏è ÂÆüË°åÁóïË∑°„Å™„Åó (Â≠òÂú®„ÅÆ„Åø)"
                
                elif "ANTI_FORENSICS" in ioc_type:
                    target_action = "üóëÔ∏è Ë®ºÊã†Èö†ÊªÖ (Wiping)"
                    
                elif "MASQUERADE" in ioc_type:
                    target_action = "üé≠ ÂÅΩË£Ö„Éï„Ç°„Ç§„É´Ë®≠ÁΩÆ"
                    
                else:
                    # Fallback
                    target_action = ioc.get("Reason", "-")

                score = ioc.get("Score", 0)
                path_short = (ioc['Path'][:30] + '..') if len(ioc['Path']) > 30 else ioc['Path']
                
                # Êñ∞„Åó„ÅÑ„Éï„Ç©„Éº„Éû„ÉÉ„Éà„ÅßÊõ∏„ÅçËæº„Åø
                f.write(f"| {str(ioc.get('Time','')).replace('T',' ')[:19]} | **{ioc['Type']}** | `{ioc['Value']}` | {target_action} | {score} | `{path_short}` |\n")
        else: f.write("No critical IOCs automatically detected.\n")
        f.write("\n")

    def _write_timeline_visual(self, f, phases):
        t = self.txt
        f.write(f"## {t['h1_time']}\n")
        f.write("‰ª•‰∏ã„Å´„ÄÅÊ§úÁü•„Åï„Çå„ÅüËÑÖÂ®Å„Ç§„Éô„É≥„Éà„ÇíÊôÇÁ≥ªÂàó„ÅßÁ§∫„Åó„Åæ„Åô„ÄÇÔºàÈáçË¶ÅÂ∫¶„Çπ„Ç≥„Ç¢80‰ª•‰∏ä„ÅÆ„Ç§„Éô„É≥„Éà„ÄÅ„Åä„Çà„Å≥Ë¶ÅÊ≥®ÊÑè„ÉÑ„Éº„É´Âà©Áî®Â±•Ê≠¥Ôºâ\n\n")
        for idx, phase in enumerate(phases):
            if not phase: continue
            if isinstance(phase[0], dict) and 'Time' in phase[0]:
                date_str = str(phase[0]['Time']).replace('T', ' ').split(' ')[0]
            else: date_str = "Unknown"
            f.write(f"### üìÖ Phase {idx+1} ({date_str})\n")
            f.write(f"| Time (UTC) | Category | Event Summary (Command / File) | Source |\n|---|---|---|---|\n") 
            for ev in phase:
                summary = ev['Summary']
                if self._is_noise(summary): continue
                time_display = str(ev.get('Time','')).replace('T', ' ').split('.')[0]
                cat_name = t['cats'].get(ev.get('Category'), ev.get('Category'))
                is_dual = self._is_dual_use(summary)
                prefix = "‚ö†Ô∏è " if is_dual else ""
                row_str = f"| {time_display} | {cat_name} | **{prefix}{summary}** | {ev['Source']} |"
                f.write(f"{row_str}\n")
            if idx < len(phases)-1: f.write("\n*( ... Time Gap ... )*\n\n")
    # [Action 2.2] Enhanced Anti-Forensics Report
    def _write_anti_forensics_section(self, f, ioc_list, dfs):
        """
        [New] Anti-ForensicsÂ∞ÇÁî®„Çª„ÇØ„Ç∑„Éß„É≥
        """
        af_tools = [ioc for ioc in ioc_list if "ANTI_FORENSICS" in str(ioc.get("Type", "")) or "WIPING" in str(ioc.get("Type", ""))]
        
        if not af_tools:
            return

        f.write("### üö® Anti-Forensics Activities (Evidence Destruction)\n\n")
        f.write("‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è **ÈáçÂ§ß„Å™Ë®ºÊã†Èö†ÊªÖÊ¥ªÂãï„ÇíÊ§úÂá∫** ‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è\n\n")
        f.write("ÊîªÊíÉËÄÖ„ÅØ‰æµÂÖ•Âæå„ÄÅ‰ª•‰∏ã„ÅÆ„ÉÑ„Éº„É´„Çí‰ΩøÁî®„Åó„Å¶Ê¥ªÂãïÁóïË∑°„ÇíÊÑèÂõ≥ÁöÑ„Å´ÊäπÊ∂à„Åó„Å¶„ÅÑ„Åæ„ÅôÔºö\n\n")

        seen_tools = set()
        
        # „ÉÑ„Éº„É´„Åî„Å®„ÅÆË©≥Á¥∞ÊÉÖÂ†±Ë°®Á§∫
        for tool in af_tools:
            name = tool.get("Value", "Unknown").upper()
            if name in seen_tools: continue
            seen_tools.add(name)
            
            run_count = self._extract_run_count(tool, dfs)
            last_run = tool.get("Time", "Unknown").replace("T", " ")[:19]
            
            desc = "„Éá„Éº„ÇøÊäπÊ∂à„ÉÑ„Éº„É´"
            if "BCWIPE" in name: desc = "Ëªç‰∫ã„É¨„Éô„É´„ÅÆ„Éï„Ç°„Ç§„É´„ÉØ„Ç§„Éî„É≥„Ç∞„ÉÑ„Éº„É´„ÄÇÈÄöÂ∏∏„ÅÆÂæ©ÂÖÉ„Çí‰∏çÂèØËÉΩ„Å´„Åó„Åæ„Åô„ÄÇ"
            elif "CCLEANER" in name: desc = "„Ç∑„Çπ„ÉÜ„É†„ÇØ„É™„Éº„Éä„Éº„ÄÇ„Éñ„É©„Ç¶„Ç∂Â±•Ê≠¥„ÇÑMRU„ÅÆÂâäÈô§„Å´‰ΩøÁî®„Åï„Çå„Åæ„Åô„ÄÇ"
            elif "SDELETE" in name: desc = "SysinternalsË£Ω„ÅÆ„Çª„Ç≠„É•„Ç¢ÂâäÈô§„ÉÑ„Éº„É´„ÄÇ"
            elif "ERASER" in name: desc = "„Éï„Ç°„Ç§„É´ÊäπÊ∂à„ÉÑ„Éº„É´„ÄÇ"

            f.write(f"#### {name}\n")
            f.write(f"- üìä **Run Count**: {run_count}Âõû\n")
            f.write(f"- üïê **Last Execution**: {last_run} (UTC)\n")
            f.write(f"- ‚ö†Ô∏è **Severity**: CRITICAL\n")
            f.write(f"- üîç **Description**: {desc}\n\n")
            
            f.write(f"üïµÔ∏è **Analyst Note**:\n")
            if "BCWIPE" in name:
                 f.write("„Åì„ÅÆ„ÉÑ„Éº„É´„ÅÆÂÆüË°å„Å´„Çà„Çä„ÄÅLNK„Éï„Ç°„Ç§„É´„ÄÅPrefetch„ÄÅ‰∏ÄÊôÇ„Éï„Ç°„Ç§„É´Á≠â„ÅÆË®ºÊã†„ÅåÁâ©ÁêÜÁöÑ„Å´‰∏äÊõ∏„ÅçÂâäÈô§„Åï„Çå„ÅüÂèØËÉΩÊÄß„ÅåÊ•µ„ÇÅ„Å¶È´ò„ÅÑ„Åß„Åô„ÄÇ\n")
            else:
                 f.write("ÊîªÊíÉÊ¥ªÂãïÁµÇ‰∫ÜÂæå„ÅÆÁóïË∑°ÂâäÈô§ÔºàCleanupÔºâ„Å´‰ΩøÁî®„Åï„Çå„Åü„Å®Êé®ÂÆö„Åï„Çå„Åæ„Åô„ÄÇ\n")
            f.write("\n---\n\n")

        # Missing Evidence Impact Table
        f.write("### üìâ Missing Evidence Impact Assessment\n\n")
        f.write("‰ª•‰∏ã„ÅÆË®ºÊã†„Åå„ÄÅAnti-Forensics„ÉÑ„Éº„É´„Å´„Çà„Å£„Å¶Â§±„Çè„Çå„Åü„Å®Âà§Êñ≠„Åï„Çå„Åæ„ÅôÔºö\n\n")
        f.write("| Ë®ºÊã†„Ç´„ÉÜ„Ç¥„É™ | ÊúüÂæÖ„Åï„Çå„ÇãÊÉÖÂ†± | ÁèæÁä∂ | Êé®ÂÆöÂéüÂõ† |\n|---|---|---|---|\n")
        f.write("| LNK Target Paths | `cmd.exe ...` Á≠â„ÅÆÂºïÊï∞ | ‚ùå Ê¨†ËêΩ | BCWipe/SDelete„Å´„Çà„ÇãÂâäÈô§ |\n")
        f.write("| Prefetch (Tools) | ÂÆüË°åÂõûÊï∞„Éª„Çø„Ç§„É†„Çπ„Çø„É≥„Éó | ‚ùå Ê¨†ËêΩ | CCleaner/BCWipe„Å´„Çà„ÇãÂâäÈô§ |\n")
        f.write("| ‰∏ÄÊôÇ„Éï„Ç°„Ç§„É´ | „Éö„Ç§„É≠„Éº„ÉâÊú¨‰Ωì | ‚ùå Ê¨†ËêΩ | „ÉØ„Ç§„Éî„É≥„Ç∞„Å´„Çà„ÇãÁâ©ÁêÜÂâäÈô§ |\n\n")

        f.write("üïµÔ∏è **Analyst Note**:\n")
        f.write("„Åì„Çå„Çâ„ÅÆË®ºÊã†Ê¨†ËêΩ„ÅØ„Äå„ÉÑ„Éº„É´„ÅÆÈôêÁïå„Äç„Åß„ÅØ„Å™„Åè„ÄÅ**„ÄåÊîªÊíÉËÄÖ„Å´„Çà„ÇãÈ´òÂ∫¶„Å™Èö†ËîΩÂ∑•‰Ωú„Äç**„ÅÆÁµêÊûú„Åß„Åô„ÄÇ\n")
        f.write("Ghost Detection (USN„Ç∏„É£„Éº„Éä„É´) „Å´„Çà„Çä„Éï„Ç°„Ç§„É´„ÅÆ„ÄåÂ≠òÂú®„Åó„Å¶„ÅÑ„Åü‰∫ãÂÆü„Äç„ÅÆ„Åø„ÇíÁ¢∫Ë™ç„Åß„Åç„Å¶„ÅÑ„Åæ„Åô„ÄÇ\n\n")

    def _extract_run_count(self, ioc, dfs):
        """
        IOC„Å´Èñ¢ÈÄ£„Åô„ÇãRunCount„ÇíÊäΩÂá∫„Åô„Çã„ÄÇ
        1. IOCËá™Ë∫´„ÅåÊåÅ„Å§Summary„Åã„ÇâÊäΩÂá∫ (Most Reliable)
        2. Prefetch DF„Åå„ÅÇ„Çå„Å∞„Åù„Åì„Åã„Çâ„ÄÇ
        3. „Å™„Åë„Çå„Å∞Timeline„ÅÆMessage„Åã„ÇâRegexÊ§úÁ¥¢„ÄÇ
        """
        # 0. Check IOC Summary (carried from Hercules)
        summary = ioc.get("Summary", "")
        if summary:
            match = re.search(r"(?:Run\s*Count:|Run:)\s*(\d+)", summary, re.IGNORECASE)
            if match: return match.group(1)

        try:
            if dfs and 'Prefetch' in dfs:
                pf_df = dfs['Prefetch']
                # Try finding by executable name
                name = ioc.get("Value", "")
                if name:
                    # Case insensitive search
                    hits = pf_df.filter(pl.col("ExecutableName").str.to_lowercase().str.contains(name.lower()))
                    if hits.height > 0:
                        return hits[0, "RunCount"]
        except: pass
        
        try:
            timeline = dfs.get("Timeline")
            if timeline is not None:
                # Filter by name and approximate time
                name = ioc.get("Value", "")
                
                # Broaden search: FileName OR Message OR Description
                cond = pl.col("FileName").str.to_lowercase().str.contains(name.lower())
                for c in ["Message", "Description", "Action"]:
                    if c in timeline.columns:
                        cond = cond | pl.col(c).str.to_lowercase().str.contains(name.lower())
                
                # Find row
                hits = timeline.filter(cond)
                if hits.height > 0:

                    # 1. Try generic column search
                    for col in hits.columns:
                        val = str(hits[0, col])
                        match = re.search(r"RunCount:\s*(\d+)", val, re.IGNORECASE)
                        if match: return match.group(1)
                        if col == "RunCount": return str(hits[0, col])
                    
                    # 2. Try bruteforce scan on stringified row (User Request)
                    try:
                        row_str = str(hits.row(0))
                        # Match 'RunCount: 1' or '(Run: 1)' or 'Run Count: 1'
                        match = re.search(r"(?:Run\s*Count:|Run:)\s*(\d+)", row_str, re.IGNORECASE)
                        if match: return match.group(1)
                    except: pass
        except: pass
        
        return "Unknown"

    def _write_technical_findings(self, f, phases):
        t = self.txt
        f.write(f"## {t['h1_tech']}\n")
        
        high_conf_events = [ioc for ioc in self.visual_iocs if self._is_force_include_ioc(ioc) or "ANTI_FORENSICS" in str(ioc.get("Type", ""))]
        
        # [Call New Section]
        self._write_anti_forensics_section(f, high_conf_events, self._latest_dfs)

        f.write("Êú¨„Çª„ÇØ„Ç∑„Éß„É≥„Åß„ÅØ„ÄÅÊ§úÂá∫„Åï„Çå„ÅüËÑÖÂ®Å„ÇíÂàÜÈ°û„Åó„Å¶Ë©≥Ëø∞„Åó„Åæ„Åô„ÄÇ\n\n")

        groups = {
            "üö® System Time Manipulation (Time Paradox)": [],
            "üé≠ File Masquerading & Backdoors": [],
            "üé£ Phishing & Initial Access (LNKs)": [],
            "‚ö° Executed Tools (Active Threats)": [],
            "üì¶ Suspicious Files (Presence Only)": [],
            "‚ö†Ô∏è Other High Confidence Threats": []
        }
        
        for ioc in high_conf_events:
            ioc_type = str(ioc.get('Type', '')).upper()
            reason = str(ioc.get('Reason', '')).upper()
            val = str(ioc.get('Value', '')).lower()
            
            # Anti-Forensics„ÅØÂ∞ÇÁî®„Çª„ÇØ„Ç∑„Éß„É≥„ÅßÊõ∏„ÅÑ„Åü„ÅÆ„Åß„Åì„Åì„Åß„ÅØ„Çπ„Ç≠„ÉÉ„Éó
            if "ANTI_FORENSICS" in ioc_type: continue 

            if "TIME_PARADOX" in ioc_type or "ROLLBACK" in reason:
                groups["üö® System Time Manipulation (Time Paradox)"].append(ioc)
            elif "MASQUERADE" in ioc_type or ".crx" in val:
                groups["üé≠ File Masquerading & Backdoors"].append(ioc)
            elif "PHISHING" in ioc_type or "SUSPICIOUS_CMDLINE" in reason or ".lnk" in val:
                groups["üé£ Phishing & Initial Access (LNKs)"].append(ioc)
            elif self._is_dual_use(val) or "DUAL_USE" in ioc_type:
                if "EXECUTION_CONFIRMED" in ioc_type or "EXEC" in reason.upper() or "PROCESS" in ioc.get("Path", "").upper():
                     groups["‚ö° Executed Tools (Active Threats)"].append(ioc)
                else:
                     groups["üì¶ Suspicious Files (Presence Only)"].append(ioc)
            else:
                groups["‚ö†Ô∏è Other High Confidence Threats"].append(ioc)

        # ... (Loop through groups and write details) ...
        for header, ioc_list in groups.items():
            if not ioc_list: continue
            f.write(f"### {header}\n")
            if "Presence Only" in header:
                f.write("> **Note:** ‰ª•‰∏ã„ÅÆ„ÉÑ„Éº„É´„ÅØ„Éá„Ç£„Çπ„ÇØ‰∏ä„Å´Â≠òÂú®„Åó„Åæ„Åô„Åå„ÄÅÊòéÁ¢∫„Å™ÂÆüË°åÁóïË∑°ÔºàPrefetch/ProcessLogÁ≠âÔºâ„ÅØÁ¢∫Ë™ç„Åï„Çå„Å¶„ÅÑ„Åæ„Åõ„Çì„ÄÇ\n\n")
            ioc_list.sort(key=lambda x: x.get('Time', '9999'))
            for ioc in ioc_list:
                dt = str(ioc.get('Time', 'Unknown')).replace('T', ' ')[:19]
                val = ioc.get('Value', 'No details')
                path = ioc.get('Path', 'Unknown')
                ioc_type = ioc.get('Type', 'Unknown')
                f.write(f"- **{dt}** | Type: `{ioc_type}` | Path: `{path[:50]}{'...' if len(path) > 50 else ''}`\n")
                insight = self._generate_ioc_insight(ioc)
                if insight: f.write(f"  - üïµÔ∏è **Analyst Note:** {insight}\n")
                f.write("\n")
        f.write("\n")
    
    def _is_force_include_ioc(self, ioc):
        force_keywords = [
            "TIME_PARADOX", "CRITICAL_MASQUERADE", "CRITICAL_PHISHING", 
            "SUSPICIOUS_CMDLINE", "CRITICAL_SIGMA", "ROLLBACK", "BACKDOOR"
        ]
        ioc_type = str(ioc.get('Type', '')).upper()
        reason = str(ioc.get('Reason', '')).upper()
        
        if any(k in ioc_type for k in force_keywords):
            return True
        if any(k in reason for k in force_keywords):
            return True
        if "DUAL-USE" in reason or "DUAL_USE" in ioc_type:
            return True
        if "TIMESTOMP" in ioc_type:
            return True
        return False
    
    # [Task 1] Updated Insight Generation using Extra (LNK Details)
    def _generate_ioc_insight(self, ioc):
        ioc_type = str(ioc.get('Type', '')).upper()
        
        if "ANTI_FORENSICS" in ioc_type:
            return "üö® **Evidence Destruction**: Ë®ºÊã†Èö†ÊªÖ„ÉÑ„Éº„É´„Åß„Åô„ÄÇÂÆüË°åÂõûÊï∞„ÇÑ„Çø„Ç§„É†„Çπ„Çø„É≥„Éó„ÇíÁ¢∫Ë™ç„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ"
        
        val = str(ioc.get('Value', ''))
        val_lower = val.lower()
        reason = str(ioc.get('Reason', '')).upper()
        path = str(ioc.get('Path', ''))



        if "EXECUTION_CONFIRMED" in ioc_type:
            return "üö® **Confirmed**: „Åì„ÅÆ„ÉÑ„Éº„É´„ÅØÂÆüÈöõ„Å´ÂÆüË°å„Åï„Çå„ÅüÁóïË∑°„Åå„ÅÇ„Çä„Åæ„Åô„ÄÇË™øÊüªÂÑ™ÂÖàÂ∫¶ÔºöÈ´ò"
        
        elif "TIME_PARADOX" in ioc_type or "ROLLBACK" in reason:
            rb_sec = "Unknown"
            if "Rollback:" in val:
                import re
                match = re.search(r"Rollback:\s*(-?\d+)", val)
                if match: rb_sec = match.group(1)
            return f"USN„Ç∏„É£„Éº„Éä„É´„ÅÆÊï¥ÂêàÊÄßÂàÜÊûê„Å´„Çà„Çä„ÄÅ„Ç∑„Çπ„ÉÜ„É†ÊôÇÂàª„ÅÆÂ∑ª„ÅçÊàª„Åó(Á¥Ñ{rb_sec}Áßí)„ÇíÊ§úÁü•„Åó„Åæ„Åó„Åü„ÄÇ„Åì„Çå„ÅØÈ´òÂ∫¶„Å™„Ç¢„É≥„ÉÅ„Éï„Ç©„É¨„É≥„Ç∏„ÉÉ„ÇØÊ¥ªÂãï„ÇíÁ§∫ÂîÜ„Åó„Åæ„Åô„ÄÇ"
        
        elif "MASQUERADE" in ioc_type or ".crx" in val_lower:
            masq_app = "Ê≠£Ë¶è„Ç¢„Éó„É™„Ç±„Éº„Ç∑„Éß„É≥"
            if "adobe" in path.lower(): masq_app = "Adobe Reader"
            elif "microsoft" in path.lower(): masq_app = "Microsoft Office"
            elif "google" in path.lower(): masq_app = "Google Chrome"
            return f"{masq_app}„ÅÆ„Éï„Ç©„É´„ÉÄ„Å´„ÄÅÁÑ°Èñ¢‰øÇ„Å™ChromeÊã°ÂºµÊ©üËÉΩ(.crx)„ÅåÈÖçÁΩÆ„Åï„Çå„Å¶„ÅÑ„Åæ„Åô„ÄÇ„Åì„Çå„ÅØÂÖ∏ÂûãÁöÑ„Å™PersistenceÔºàÊ∞∏Á∂öÂåñÔºâÊâãÊ≥ï„Åß„Åô„ÄÇ"
        
        elif ".lnk" in val_lower and ("SUSPICIOUS" in ioc_type or "PHISHING" in ioc_type or "PS_" in ioc_type or "CMD_" in ioc_type or "MSHTA" in ioc_type):
            insights = []
            extra = ioc.get('Extra', {})
            target = extra.get('Target_Path', '')
            args = extra.get('Arguments', '')
            risk = extra.get('Risk', '')

            # 1. Target Information
            if not target:
                if "Target:" in val: target = val.split("Target:")[-1].strip()
                elif "üéØ" in val: target = val.split("üéØ")[-1].strip()
            
            if target:
                insights.append(f"üéØ **Target**: `{target}`")
                
                # Dynamic Severity Analysis
                if "cmd.exe" in target.lower() or "powershell" in target.lower():
                     insights.append("‚ö†Ô∏è **Critical**: OSÊ®ôÊ∫ñ„Ç∑„Çß„É´„ÇíÊÇ™Áî®„Åó„ÅüÊîªÊíÉ„ÅÆËµ∑ÁÇπ„Åß„Åô„ÄÇ")
                elif ".exe" in target.lower() or ".bat" in target.lower() or ".vbs" in target.lower():
                     insights.append("‚ö†Ô∏è **High**: ÂÆüË°åÂèØËÉΩ„Éï„Ç°„Ç§„É´„ÇíÂëº„Å≥Âá∫„Åô„Ç∑„Éß„Éº„Éà„Ç´„ÉÉ„Éà„Åß„Åô„ÄÇ")

            # 2. Argument Analysis
            if args:
                # Èï∑„Åô„Åé„ÇãÂ†¥Âêà„ÅØÁúÅÁï•Ë°®Á§∫
                args_disp = (args[:100] + "...") if len(args) > 100 else args
                insights.append(f"üìù **Args**: `{args_disp}`")
                
                # Critical Flags Identification
                if "-enc" in args.lower() or "-encoded" in args.lower():
                    insights.append("üö´ **Encoded**: Base64„Ç®„É≥„Ç≥„Éº„Éâ„Åï„Çå„ÅüPowerShell„Ç≥„Éû„É≥„Éâ„ÇíÊ§úÁü•„ÄÇÂç≥Â∫ß„Å´Ëß£Êûê„ÅåÂøÖË¶Å„Åß„Åô„ÄÇ")
                if "-windowstyle hidden" in args.lower() or "-w hidden" in args.lower():
                    insights.append("üï∂Ô∏è **Stealth**: „É¶„Éº„Ç∂„Éº„Åã„Çâ„Ç¶„Ç£„É≥„Éâ„Ç¶„ÇíÈö†ËîΩ„Åô„Çã„Éï„É©„Ç∞„ÇíÁ¢∫Ë™ç„ÄÇ")
            else:
                 # ÂºïÊï∞„ÅåÂèñ„Çå„Å™„Åè„Å¶„ÇÇ„Çø„Éº„Ç≤„ÉÉ„Éà„Éë„Çπ„Å´ÂºïÊï∞„ÅåÂê´„Åæ„Çå„Å¶„ÅÑ„ÇãÂ†¥Âêà„ÅÆ„Éï„Ç©„Éº„É´„Éê„ÉÉ„ÇØ
                 if "-enc" in target.lower():
                      insights.append("üö´ **Encoded**: „Çø„Éº„Ç≤„ÉÉ„Éà„Éë„ÇπÂÜÖ„Å´„Ç®„É≥„Ç≥„Éº„Éâ„Åï„Çå„Åü„Ç≥„Éû„É≥„Éâ„ÇíÁ¢∫Ë™ç„ÄÇ")

            # 3. Special Flags (Masquerade)
            if risk == "SECURITY_TOOL_MASQUERADE":
                insights.append("üé≠ **Masquerade**: „Çª„Ç≠„É•„É™„ÉÜ„Ç£„ÉÑ„Éº„É´„ÇÑ„Ç´„É≥„Éï„Ç°„É¨„É≥„ÇπË≥áÊñô(DEFCONÁ≠â)„Å∏„ÅÆÂÅΩË£Ö„ÅåÁñë„Çè„Çå„Åæ„Åô„ÄÇ")

            if insights:
                return "<br/>".join(insights)
            elif "PHISHING" in ioc_type:
                return "‰∏çÂØ©„Å™„Ç∑„Éß„Éº„Éà„Ç´„ÉÉ„Éà„Éï„Ç°„Ç§„É´„Åå‰ΩúÊàê„Åï„Çå„Åæ„Åó„Åü„ÄÇ„Éï„Ç£„ÉÉ„Ç∑„É≥„Ç∞ÊîªÊíÉ„ÅÆÂèØËÉΩÊÄß„Åå„ÅÇ„Çä„Åæ„Åô„ÄÇ"
            else:
                return "‰∏çÂØ©„Å™„Ç∑„Éß„Éº„Éà„Ç´„ÉÉ„Éà„Éï„Ç°„Ç§„É´„ÇíÊ§úÁü•„Åó„Åæ„Åó„Åü„ÄÇ"
        
        elif "PHISHING" in ioc_type:
            return "„Éï„Ç£„ÉÉ„Ç∑„É≥„Ç∞Ê¥ªÂãï„Å´Èñ¢ÈÄ£„Åô„Çã„Ç¢„Éº„ÉÜ„Ç£„Éï„Ç°„ÇØ„Éà„ÇíÊ§úÁü•„Åó„Åæ„Åó„Åü„ÄÇ"
        
        elif "TIMESTOMP" in ioc_type:
            tool_name = val.split()[0] if val else "Unknown"
            return f"`{tool_name}` „ÅÆ„Çø„Ç§„É†„Çπ„Çø„É≥„Éó„Å´‰∏çÊï¥ÂêàÔºàTimestompÔºâ„ÇíÁ¢∫Ë™ç„ÄÇÊîªÊíÉ„ÉÑ„Éº„É´„ÇíÈö†ËîΩ„Åó„Çà„ÅÜ„Å®„Åó„ÅüÁóïË∑°„Åß„Åô„ÄÇ"
        
        elif "CREDENTIALS" in ioc_type:
            return "Ë™çË®ºÊÉÖÂ†±„ÅÆÁ™ÉÂèñ„Åæ„Åü„ÅØ‰∏çÊ≠£„ÉÑ„Éº„É´„ÅÆÈÖçÁΩÆ„ÇíÊ§úÁü•„Åó„Åæ„Åó„Åü„ÄÇ"
        
        elif "COMMUNICATION_CONFIRMED" in reason or "COMMUNICATION_CONFIRMED" in ioc_type:
            return "üö® „Éñ„É©„Ç¶„Ç∂Â±•Ê≠¥„Å®„ÅÆÁÖßÂêà„Å´„Çà„Çä„ÄÅ**ÂÆüÈöõ„Å´„Éç„ÉÉ„Éà„ÉØ„Éº„ÇØÈÄö‰ø°„ÅåÊàêÂäü„Åó„ÅüÁóïË∑°**„ÇíÁ¢∫Ë™ç„Åó„Åæ„Åó„Åü„ÄÇC2„Çµ„Éº„Éê„Å∏„ÅÆ„Éì„Éº„Ç≥„É≥ÈÄÅ‰ø°„ÄÅ„Åæ„Åü„ÅØ„Éö„Ç§„É≠„Éº„Éâ„ÉÄ„Ç¶„É≥„É≠„Éº„Éâ„ÅÆÂèØËÉΩÊÄß„ÅåÊ•µ„ÇÅ„Å¶È´ò„ÅÑ„Åß„Åô„ÄÇ"
        
        return None

    def _generate_mermaid(self):
        if not self.visual_iocs: return ""
        
        def get_time(item):
            t = item.get("Time", "")
            return t if t else "9999"
            
        sorted_iocs = sorted(self.visual_iocs, key=get_time)
        if not sorted_iocs: return ""
        
        has_paradox = any("TIME_PARADOX" in str(ioc.get("Type", "")) for ioc in self.visual_iocs)
        
        rollback_time_str = None
        if has_paradox:
            for ioc in self.visual_iocs:
                if "TIME_PARADOX" in str(ioc.get("Type", "")):
                    rollback_time_str = str(ioc.get("Time", ""))[:10]
                    break
        
        chart = "\n```mermaid\ngraph TD\n"
        chart += "    %% Time-Clustered Attack Flow\n"
        chart += "    start((Start)) --> P0\n"
        
        clusters = []
        current_cluster = []
        last_dt = None
        for ioc in sorted_iocs[:25]:
            if self._is_visual_noise(ioc["Value"]): continue
            ts_str = ioc.get("Time", "")
            curr_dt = self._parse_time_safe(ts_str)
            if curr_dt:
                if last_dt and (curr_dt - last_dt).total_seconds() > 60: 
                    clusters.append(current_cluster)
                    current_cluster = []
                last_dt = curr_dt
            current_cluster.append(ioc)
        if current_cluster: clusters.append(current_cluster)

        node_registry = []
        for idx, cluster in enumerate(clusters):
            if not cluster: continue
            
            time_label = "Unknown"
            if cluster[0].get("Time"):
                time_str = str(cluster[0]["Time"])
                if "T" in time_str: time_label = time_str.split("T")[1][:5]
                elif " " in time_str: time_label = time_str.split(" ")[1][:5]
                else: time_label = time_str[-8:-3]
            
            cluster_is_fake = False
            if has_paradox and rollback_time_str:
                cluster_time = str(cluster[0].get("Time", ""))[:10]
                if cluster_time and cluster_time < rollback_time_str:
                    if any(x in time_label for x in ["00:", "01:", "02:", "03:"]):
                        cluster_is_fake = True
                        time_label += " ‚ö†Ô∏è(FAKE?)"

            chart += f"\n    subgraph T{idx} [Time: {time_label}]\n"
            chart += "        direction TB\n"
            
            for item in cluster:
                val = self._sanitize_mermaid(item["Value"])
                typ = item["Type"]
                
                if "TIME_PARADOX" in typ: short_val = "SYSTEM ROLLBACK"
                else: short_val = (val[:15] + '..') if len(val) > 15 else val
                
                icon = "üíÄ"
                if "PHISH" in typ: icon = "üé£"
                elif "BACKDOOR" in typ or "MASQ" in typ: icon = "üé≠"
                elif "TIME_PARADOX" in typ: icon = "‚è™"
                elif "TIMESTOMP" in typ: icon = "üïí"
                elif "PERSIST" in typ: icon = "‚öì"
                
                style_class = "threat"
                if cluster_is_fake: style_class = "fake"
                if "TIME_PARADOX" in typ: style_class = "paradox"

                node_id = f"N{abs(hash(val + str(idx)))}"
                label = f"{icon} {typ}<br/>{short_val}"
                chart += f"        {node_id}[\"{label}\"]\n"
                node_registry.append({"id": node_id, "style": style_class})
            
            chart += "    end\n"
            
            if idx > 0 and node_registry:
                prev_node = node_registry[-len(cluster)-1]["id"] if len(node_registry) > len(cluster) else node_registry[0]["id"]
                curr_node = node_registry[-len(cluster)]["id"]
                chart += f"    {prev_node} --> {curr_node}\n"
            elif node_registry:
                chart += f"    P0 --> {node_registry[0]['id']}\n"

        chart += "\n    %% Styles\n"
        chart += "    classDef threat fill:#ffcccc,stroke:#ff0000,stroke-width:2px,color:#000;\n"
        chart += "    classDef fake fill:#eeeeee,stroke:#999999,stroke-dasharray: 5 5,color:#666;\n"
        chart += "    classDef paradox fill:#ffffcc,stroke:#ffcc00,stroke-width:4px,color:#000;\n"
        
        for node in node_registry:
            chart += f"    class {node['id']} {node['style']};\n"
            
        chart += "```\n"
        return chart

    def _sanitize_mermaid(self, text):
        clean = str(text).replace('"', "'").replace("{", "(").replace("}", ")")
        clean = clean.replace("<", "&lt;").replace(">", "&gt;")
        return clean

    def _write_detection_statistics(self, f, medium_events, dfs):
        t = self.txt
        f.write(f"## {t['h1_stats']}\n")
        f.write("Êú¨„Çª„ÇØ„Ç∑„Éß„É≥„Åß„ÅØ„ÄÅCritical„Å´„ÅØËá≥„Çâ„Å™„Åã„Å£„Åü„ÇÇ„ÅÆ„ÅÆ„ÄÅË™øÊüª„ÅÆÂèÇËÄÉ„Å®„Å™„Çã‰∏≠Á¢∫Â∫¶ÔºàMedium ConfidenceÔºâ„ÅÆ„Ç§„Éô„É≥„ÉàÂèä„Å≥„Éï„Ç£„É´„Çø„É™„É≥„Ç∞Áµ±Ë®à„ÇíÁ§∫„Åó„Åæ„Åô„ÄÇ\n\n")
        if medium_events:
            f.write(f"**Medium Confidence Events:** {len(medium_events)} ‰ª∂ (Timeline CSVÂèÇÁÖß)\n")
            f.write("| Time | Summary |\n|---|---|\n")
            for ev in medium_events[:5]:
                t_str = str(ev.get('Time','')).replace('T',' ')[:19]
                sum_str = str(ev.get('Summary', ''))[:80] + "..."
                f.write(f"| {t_str} | {sum_str} |\n")
            f.write("\n")
        f.write("### üìâ Filtered Noise Statistics\n")
        f.write("| Filter Reason | Count |\n|---|---|\n")
        if self.noise_stats:
            for reason, count in sorted(self.noise_stats.items(), key=lambda x: x[1], reverse=True):
                f.write(f"| {reason} | {count} |\n")
        else: f.write("| No noise filtered | 0 |\n")
        f.write("\n")

    def _write_ioc_appendix_unified(self, f):
        t = self.txt
        f.write(f"## {t['h1_app']} (Full IOC List)\n")
        f.write("Êú¨Ë™øÊüª„ÅßÁ¢∫Ë™ç„Åï„Çå„Åü„Åô„Åπ„Å¶„ÅÆ‰æµÂÆ≥ÊåáÊ®ôÔºàIOCÔºâ„ÅÆ‰∏ÄË¶ß„Åß„Åô„ÄÇ\n\n")
        if self.visual_iocs:
            f.write("### üìÇ File IOCs (Malicious/Suspicious Files)\n")
            f.write("| File Name | Path | Source | Note |\n|---|---|---|---|\n")
            seen = set()
            sorted_iocs = sorted(self.visual_iocs, key=lambda x: 0 if "CRITICAL" in x.get("Reason", "").upper() else 1)
            for ioc in sorted_iocs:
                val = ioc['Value']
                path = ioc['Path']
                if self._is_visual_noise(val): continue
                key = f"{val}|{path}"
                if key in seen: continue
                seen.add(key)
                reason = ioc.get("Reason", "Unknown")
                f.write(f"| `{val}` | `{path}` | {ioc['Type']} ({reason}) | {ioc.get('Time', 'N/A')} |\n")
            f.write("\n")
        if self.infra_ips_found:
            f.write("### üåê Network IOCs (Suspicious Connections)\n")
            f.write("| Remote IP | Context |\n|---|---|\n")
            for ip in self.infra_ips_found:
                 f.write(f"| `{ip}` | Detected in Event Logs |\n")
            f.write("\n")

    def _collect_file_iocs(self, dfs):
        return []

    def _default_insight(self, ev):
        summary = ev['Summary'].lower()
        if "timestomp" in summary: return "„Éï„Ç°„Ç§„É´„Çø„Ç§„É†„Çπ„Çø„É≥„Éó„ÅÆÊîπ„Åñ„ÇìÁóïË∑°„Åß„Åô„ÄÇ"
        return "‰∏çÂØ©„Å™„Ç¢„ÇØ„ÉÜ„Ç£„Éì„ÉÜ„Ç£„ÇíÊ§úÁü•„Åó„Åæ„Åó„Åü„ÄÇ"

    def _add_unique_visual_ioc(self, ioc_dict):
        if self._is_noise(ioc_dict["Value"], ioc_dict["Path"]): return
        for existing in self.visual_iocs:
            if existing["Value"] == ioc_dict["Value"] and existing["Type"] == ioc_dict["Type"]: return
        self.visual_iocs.append(ioc_dict)

    def _generate_pivot_seeds(self):
        for ioc in self.visual_iocs:
            self.pivot_seeds.append({
                "Target_File": ioc["Value"],
                "Target_Path": ioc.get("Path", ""),
                "Reason": ioc.get("Reason", ioc["Type"]),
                "Timestamp_Hint": ioc.get("Time", "")
            })

    def _export_pivot_config(self, path, primary_user):
        if not self.pivot_seeds: return
        config = {
            "Case_Context": {
                "Hostname": self.hostname,
                "Primary_User": primary_user,
                "Generated_At": datetime.now().isoformat()
            },
            "Deep_Dive_Targets": self.pivot_seeds[:20]
        }
        try:
            with open(path, "w", encoding="utf-8") as f:
                json.dump(config, f, indent=2, ensure_ascii=False)
            print(f"    -> [Lachesis] Pivot Config generated: {path}")
        except Exception as e:
            print(f"    [!] Failed to export Pivot Config: {e}")

    def _export_json_grimoire(self, analysis_result, dfs_for_ioc, json_path, primary_user):
        serializable_events = []
        for ev in analysis_result["events"]:
            serializable_events.append({
                "Time": str(ev.get('dt_obj', ev['Time'])),
                "User": ev.get('User'),
                "Category": ev.get('Category'),
                "Summary": ev.get('Summary'),
                "Source": ev.get('Source'),
                "Criticality": ev.get('Criticality', 0)
            })
        iocs = {"File": self.visual_iocs, "Network": list(self.infra_ips_found), "Cmd": []}
        grimoire_data = {
            "Metadata": {"Host": self.hostname, "Case": self.case_name, "Primary_User": primary_user, "Generated_At": datetime.now().isoformat()},
            "Verdict": {"Flags": list(analysis_result["verdict_flags"]), "Lateral_Summary": analysis_result["lateral_summary"]},
            "Timeline": serializable_events,
            "IOCs": iocs
        }
        try:
            with open(json_path, "w", encoding="utf-8") as f:
                json.dump(grimoire_data, f, indent=2, ensure_ascii=False)
            print(f"    -> [Chimera Ready] JSON Grimoire saved: {json_path}")
        except Exception as e:
            print(f"    [!] Failed to export JSON Grimoire: {e}")

if __name__ == "__main__":
    pass